{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import csv\n",
    "import math\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_topics=[]\n",
    "ques_groups={}\n",
    "ans_groups={}\n",
    "topic_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_topics():\n",
    "    topics = []\n",
    "    count=0\n",
    "    with open('item_id_q_tags.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            topics.append(row[1])\n",
    "            if row[1] in topic_dict:\n",
    "                t=1\n",
    "            else:\n",
    "                topic_dict[row[1]]=count\n",
    "                count += 1\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data(topics):\n",
    "    test_data = {}\n",
    "    for filename in os.listdir('./kahi_unkahi_ques'):\n",
    "        filenumber = int(filename[4:-4])\n",
    "        filename = './kahi_unkahi_ques/' + filename\n",
    "        doc = open(filename,encoding='UTF-8').read()\n",
    "        doc = doc[:-1]\n",
    "        topic = topics[filenumber]\n",
    "        if(topic in ques_groups):\n",
    "            ques_groups[topic].append(filenumber)\n",
    "        else:\n",
    "            temp = []\n",
    "            ques_groups[topic]=temp\n",
    "            ques_groups[topic].append(filenumber)\n",
    "        if topic in test_data:\n",
    "            test_data[topic] = test_data[topic] + \" \" + doc\t\n",
    "        else:\n",
    "            test_data[topic] = doc\n",
    "    count = 0\n",
    "    c = 0\n",
    "    for filename in os.listdir('./kahi_unkahi_ans'):\n",
    "        filenumber = int(filename[4:-4])\n",
    "        filename = './kahi_unkahi_ans/' + filename\n",
    "        doc = open(filename,encoding='UTF-8').read()\n",
    "        #doc = doc.decode(\"utf-8\")\n",
    "        if(doc == \"\"):\n",
    "            continue\n",
    "        c+=1\n",
    "        words = doc.splitlines()\n",
    "        words = words[3:]\t\t\n",
    "        output = \"\"\n",
    "        for word in words:\n",
    "            temp = word.split()\n",
    "            count = 0\n",
    "            for a in temp:\n",
    "                if(count == 2):\n",
    "                    output += a\n",
    "                    output += \" \"\n",
    "                if(a == '-'):\n",
    "                    count = count+1\n",
    "            if(output==\"\"):continue\n",
    "        topic = topics[filenumber]\n",
    "        if(topic in ans_groups):\n",
    "            ans_groups[topic].append(filenumber)\n",
    "        else:\n",
    "            temp = []\n",
    "            ans_groups[topic]=temp\n",
    "            ans_groups[topic].append(filenumber)\n",
    "    data = []\n",
    "    for key in test_data.keys():\n",
    "        #print(key)\n",
    "        if(key == \"\"):\n",
    "            print(test_data[key])\n",
    "        temp_topics.append(key)\n",
    "        data.append(test_data[key])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    for i in range(0, len(data)):\n",
    "        temp=\"\"\n",
    "        for j in range(0, len(data[i])):\n",
    "            if(data[i][j] != ',' and data[i][j] != ')' and data[i][j] != '(' and data[i][j] != '\"' and data[i][j] != ':' and data[i][j] != '%' and not(data[i][j] >= '0' and data[i][j] <= '9') and data[i][j] != '-' and data[i][j] != '/' and not(data[i][j] >= 'a' and data[i][j] <= 'z') and not(data[i][j] >= 'A'  and data[i][j] <= 'Z') and data[i][j] != '/' and data[i][j] != '-'):\n",
    "                temp=temp+data[i][j]\n",
    "        data[i]=temp\n",
    "    new_data=data\n",
    "    for i in range(0, len(new_data)):\n",
    "        if(i == 0):\n",
    "            continue\n",
    "        temp = new_data[i].split()\n",
    "        le = len(temp)\n",
    "        if(le !=0 and temp[le - 1] == '?'):\n",
    "            out = \"\"\n",
    "            for j in range(le-1):\n",
    "                out += temp[j]\n",
    "                out += \" \"\n",
    "            new_data[i] = out\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(data):\n",
    "    stop_file=open(\"stopwords-hi.txt\",encoding='UTF-8').read()\n",
    "    #stop_file=stop_file.decode(\"utf-8\")\n",
    "    stopwords=stop_file.split()\n",
    "    dictionary={}\n",
    "    for word in stopwords:\n",
    "        dictionary[word]=1\n",
    "    for i in  range(len(data)):\n",
    "        temp=\"\"\n",
    "        arr=data[i].split()\n",
    "        for j in range(len(arr)):\n",
    "            if(arr[j] not in dictionary):temp+=(arr[j] + \" \")\n",
    "        data[i]=temp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, counts in wordDict.items():\n",
    "        tfDict[word] = counts/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makewordDict(data):\n",
    "    dictionary = {}\n",
    "    line = data.split()\n",
    "    for word in line:\n",
    "        if word in dictionary:\n",
    "            dictionary[word] = dictionary[word] + 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTF(data):\n",
    "    answer = []\n",
    "    for bow in data:\n",
    "        dictionary = makewordDict(bow)\n",
    "        tfDict = computeTF(dictionary, bow)\n",
    "        answer.append(tfDict)\n",
    "    print(len(data))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(data):\n",
    "    idfDict = {}\n",
    "    for bow in data:\n",
    "        line = bow.split()\n",
    "        my_set = set(line)\n",
    "        for word in my_set:\n",
    "            if word in idfDict:\n",
    "                idfDict[word] += 1\n",
    "            else:\n",
    "                idfDict[word] = 1\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(len(data) / float(val)) \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfbow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfbow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTFIDF(tfdata, idfdata):\n",
    "    answer = []\n",
    "    for tfbow in tfdata:\n",
    "        answer.append(computeTFIDF(tfbow, idfdata))\n",
    "    print (len(answer))\n",
    "    print (len(tfdata))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracymeasure():\n",
    "    count = 0\n",
    "    c = 0\n",
    "    test_data = []\n",
    "    test_data_filenumber = []\n",
    "    for filename in os.listdir('./kahi_unkahi_ans'):\n",
    "        filenumber = int(filename[4:-4])\n",
    "        filename = './kahi_unkahi_ans/' + filename\n",
    "        doc = open(filename,encoding='UTF-8').read()\n",
    "        #doc = doc.decode(\"utf-8\")\n",
    "        if(doc == \"\"):\n",
    "            continue\n",
    "        c+=1\n",
    "        words = doc.splitlines()\n",
    "        words = words[3:]\n",
    "        output = \"\"\n",
    "        for word in words:\n",
    "            temp = word.split()\n",
    "            count = 0\n",
    "            for a in temp:\n",
    "                if(count == 2):\n",
    "                    output += a\n",
    "                    output += \" \"\n",
    "                if(a == '-'):\n",
    "                    count = count+1\n",
    "            if(output==\"\"):continue\n",
    "        topic = topics[filenumber]\n",
    "        test_data_filenumber.append(filenumber)\n",
    "        test_data.append(output)\n",
    "    test_data=cleaning(test_data)\n",
    "\n",
    "    test_data=stopwords_removal(test_data)\n",
    "    split_test_data=[]\n",
    "    for i in range(0, len(test_data)):\n",
    "        temp=test_data[i]\n",
    "        temp=temp.split()\n",
    "        split_test_data.append(temp)\n",
    "    correct=0\n",
    "    total=0\n",
    "#     print (len(split_test_data))\n",
    "    \n",
    "    prediction_matrix = []\n",
    "    real_matrix = []\n",
    "    for i in range(0,len(split_test_data)):\n",
    "        temp=[]\n",
    "        for j in range(0, len(topic_dict)):\n",
    "            temp.append(0)\n",
    "        prediction_matrix.append(temp)\n",
    "        temp=[]\n",
    "        for j in range(0, len(topic_dict)):\n",
    "            temp.append(0)\n",
    "        real_matrix.append(temp)\n",
    "        max_score=0.0\n",
    "        max_index=-1\n",
    "        score_table = {}\n",
    "        for j in range(1, len(temp_topics)-1):\n",
    "            score_table[temp_topics[j]] = 0.0\n",
    "        for j in range(0, len(sorted_tfidfdata)):\n",
    "            tfidf=sorted_tfidfdata[j]\n",
    "            curr_score=0.0\n",
    "            for k in range(0, len(split_test_data[i])):\n",
    "                word=split_test_data[i][k]\n",
    "                for word1, val1 in tfidf.items():\n",
    "                    if(word == word1):\n",
    "                        curr_score=curr_score+val1\n",
    "                        break\n",
    "            sum1=0.0\n",
    "            for word1, val1 in tfidf.items():\n",
    "                sum1=sum1+val1\n",
    "            if(sum1==0):\n",
    "                sum1=1\n",
    "            curr_score = curr_score/sum1\n",
    "            score_table[temp_topics[j+1]]=curr_score\n",
    "            if(curr_score > max_score):\n",
    "                max_score=curr_score\n",
    "                max_index=j\n",
    "        test_data_topic=temp_topics[max_index+1]\n",
    "        real_data_topic=topics[test_data_filenumber[i]]\n",
    "        test_data_topic_index=topic_dict[test_data_topic]\n",
    "        real_data_topic_index=topic_dict[real_data_topic]\n",
    "        prediction_matrix[i][test_data_topic_index]=1\n",
    "        real_matrix[i][real_data_topic_index]=1\n",
    "        to_find = test_data_filenumber[i]\n",
    "        check=0\n",
    "        for j in range(0, len(ques_groups[test_data_topic])):\n",
    "            if(to_find == ques_groups[test_data_topic][j]):\n",
    "                check=1\n",
    "                break\n",
    "        if(check == 1):\n",
    "            correct = correct + 1\n",
    "            # print \"matched\"\n",
    "        totall = total + 1\n",
    "#     print(correct)\n",
    "#     print(total)\n",
    "    print (correct/len(test_data))\n",
    "    global_true_positives=1\n",
    "    global_false_positives=1\n",
    "    global_true_negatives=1\n",
    "    global_false_negatives=1\n",
    "    for topic in topic_dict.keys():\n",
    "        topic_index=topic_dict[topic]\n",
    "        true_positives=1\n",
    "        false_positives=1\n",
    "        true_negatives=1\n",
    "        false_negatives=1\n",
    "        for i in range(0, len(prediction_matrix)):\n",
    "            if(prediction_matrix[i][topic_index] == 1):\n",
    "                if(prediction_matrix[i][topic_index] == real_matrix[i][topic_index]):\n",
    "                    true_positives +=1\n",
    "                    global_true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "                    global_false_positives += 1\n",
    "            else:\n",
    "                if(prediction_matrix[i][topic_index] == real_matrix[i][topic_index]):\n",
    "                    true_negatives += 1\n",
    "                    global_true_negatives += 1\n",
    "                else:\n",
    "                    false_negatives += 1\n",
    "                    global_false_negatives += 1\n",
    "        accuracy = (true_positives + true_negatives)/(true_positives + true_negatives + false_positives + false_negatives)\n",
    "        precision = true_positives/(true_positives + false_positives)\n",
    "        recall = true_positives/(true_positives + false_negatives)\n",
    "        f1_score = 2/((1/precision) + (1/recall))\n",
    "        print( \"Topic : \", topic)\n",
    "        print (\"ACcuracy : \", accuracy*100.0)\n",
    "        print (\"Precision : \", precision*100.0)\n",
    "        print (\"Recall : \", recall*100.0)\n",
    "        print (\"F1_score : \", f1_score*100.0)\n",
    "    accuracy = (global_true_positives + global_true_negatives)/(global_true_positives + global_true_negatives + global_false_positives + global_false_negatives)\n",
    "    precision = global_true_positives/(global_true_positives + global_false_positives)\n",
    "    recall = global_true_positives/(global_true_positives + global_false_negatives)\n",
    "    f1_score = 2/((1/precision) + (1/recall))\n",
    "    print( \"ACcuracy : \", accuracy*100.0)\n",
    "    print (\"Precision : \", precision*100.0)\n",
    "    print (\"Recall : \", recall*100.0)\n",
    "    print( \"F1_score : \", f1_score*100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "38\n",
      "38\n",
      "38\n",
      "0.012987012987012988\n",
      "Topic :  First period\n",
      "ACcuracy :  95.64516129032258\n",
      "Precision :  4.545454545454546\n",
      "Recall :  14.285714285714285\n",
      "F1_score :  6.896551724137931\n",
      "Topic :  Irregular periods\n",
      "ACcuracy :  98.06451612903226\n",
      "Precision :  28.57142857142857\n",
      "Recall :  22.22222222222222\n",
      "F1_score :  25.0\n",
      "Topic :  Other\n",
      "ACcuracy :  93.54838709677419\n",
      "Precision :  50.0\n",
      "Recall :  2.5\n",
      "F1_score :  4.761904761904762\n",
      "Topic :  STDs\n",
      "ACcuracy :  98.38709677419355\n",
      "Precision :  33.33333333333333\n",
      "Recall :  11.11111111111111\n",
      "F1_score :  16.666666666666664\n",
      "Topic :  Masturbation\n",
      "ACcuracy :  93.2258064516129\n",
      "Precision :  22.22222222222222\n",
      "Recall :  5.405405405405405\n",
      "F1_score :  8.695652173913043\n",
      "Topic :  Pregnancy\n",
      "ACcuracy :  93.2258064516129\n",
      "Precision :  11.11111111111111\n",
      "Recall :  2.857142857142857\n",
      "F1_score :  4.545454545454546\n",
      "Topic :  Sex\n",
      "ACcuracy :  56.12903225806451\n",
      "Precision :  25.0\n",
      "Recall :  0.7462686567164178\n",
      "F1_score :  1.4492753623188406\n",
      "Topic :  Other sexual health issues\n",
      "ACcuracy :  86.45161290322581\n",
      "Precision :  50.0\n",
      "Recall :  1.1904761904761905\n",
      "F1_score :  2.3255813953488373\n",
      "Topic :  Feedback_suggestion\n",
      "ACcuracy :  98.87096774193549\n",
      "Precision :  16.666666666666664\n",
      "Recall :  33.33333333333333\n",
      "F1_score :  22.22222222222222\n",
      "Topic :  Attraction\n",
      "ACcuracy :  92.41935483870968\n",
      "Precision :  4.545454545454546\n",
      "Recall :  28.57142857142857\n",
      "F1_score :  7.8431372549019605\n",
      "Topic :  Contraceptives\n",
      "ACcuracy :  96.61290322580646\n",
      "Precision :  33.33333333333333\n",
      "Recall :  5.0\n",
      "F1_score :  8.695652173913043\n",
      "Topic :  Puberty\n",
      "ACcuracy :  99.03225806451613\n",
      "Precision :  20.0\n",
      "Recall :  33.33333333333333\n",
      "F1_score :  25.0\n",
      "Topic :  \\N\n",
      "ACcuracy :  94.51612903225806\n",
      "Precision :  5.555555555555555\n",
      "Recall :  5.555555555555555\n",
      "F1_score :  5.555555555555555\n",
      "Topic :  Love and relationship\n",
      "ACcuracy :  88.87096774193549\n",
      "Precision :  4.878048780487805\n",
      "Recall :  6.25\n",
      "F1_score :  5.47945205479452\n",
      "Topic :  Pre-mature ejaculation_Nightfall\n",
      "ACcuracy :  95.96774193548387\n",
      "Precision :  33.33333333333333\n",
      "Recall :  4.166666666666666\n",
      "F1_score :  7.4074074074074066\n",
      "Topic :  Physical changes\n",
      "ACcuracy :  97.90322580645162\n",
      "Precision :  23.076923076923077\n",
      "Recall :  50.0\n",
      "F1_score :  31.578947368421055\n",
      "Topic :  Male\n",
      "ACcuracy :  90.80645161290323\n",
      "Precision :  5.555555555555555\n",
      "Recall :  8.0\n",
      "F1_score :  6.557377049180328\n",
      "Topic :  \n",
      "ACcuracy :  99.03225806451613\n",
      "Precision :  16.666666666666664\n",
      "Recall :  50.0\n",
      "F1_score :  25.0\n",
      "Topic :  Talk\n",
      "ACcuracy :  95.96774193548387\n",
      "Precision :  4.166666666666666\n",
      "Recall :  33.33333333333333\n",
      "F1_score :  7.4074074074074066\n",
      "Topic :  Cramp and pain (stress) \n",
      "ACcuracy :  97.41935483870968\n",
      "Precision :  9.090909090909092\n",
      "Recall :  14.285714285714285\n",
      "F1_score :  11.11111111111111\n",
      "Topic :  Relationship with parents \n",
      "ACcuracy :  97.58064516129032\n",
      "Precision :  7.142857142857142\n",
      "Recall :  33.33333333333333\n",
      "F1_score :  11.76470588235294\n",
      "Topic :  Health during periods\n",
      "ACcuracy :  99.35483870967742\n",
      "Precision :  50.0\n",
      "Recall :  25.0\n",
      "F1_score :  33.33333333333333\n",
      "Topic :  White discharge\n",
      "ACcuracy :  92.74193548387096\n",
      "Precision :  3.125\n",
      "Recall :  6.666666666666667\n",
      "F1_score :  4.25531914893617\n",
      "Topic :  Marital rape\n",
      "ACcuracy :  65.16129032258064\n",
      "Precision :  0.4629629629629629\n",
      "Recall :  50.0\n",
      "F1_score :  0.9174311926605505\n",
      "Topic :  Use and disposal of pads\n",
      "ACcuracy :  99.19354838709677\n",
      "Precision :  20.0\n",
      "Recall :  50.0\n",
      "F1_score :  28.57142857142857\n",
      "Topic :  Child sexual and physical abuse \n",
      "ACcuracy :  87.09677419354838\n",
      "Precision :  1.25\n",
      "Recall :  50.0\n",
      "F1_score :  2.4390243902439024\n",
      "Topic :  Question\n",
      "ACcuracy :  98.06451612903226\n",
      "Precision :  8.333333333333332\n",
      "Recall :  50.0\n",
      "F1_score :  14.285714285714285\n",
      "Topic :  Opinion\n",
      "ACcuracy :  99.35483870967742\n",
      "Precision :  25.0\n",
      "Recall :  50.0\n",
      "F1_score :  33.33333333333333\n",
      "Topic :  Domestic violence\n",
      "ACcuracy :  99.35483870967742\n",
      "Precision :  25.0\n",
      "Recall :  50.0\n",
      "F1_score :  33.33333333333333\n",
      "Topic :  Health\n",
      "ACcuracy :  99.51612903225806\n",
      "Precision :  33.33333333333333\n",
      "Recall :  50.0\n",
      "F1_score :  40.0\n",
      "Topic :  Appreciation\n",
      "ACcuracy :  99.35483870967742\n",
      "Precision :  25.0\n",
      "Recall :  50.0\n",
      "F1_score :  33.33333333333333\n",
      "Topic :  Unwanted touch\n",
      "ACcuracy :  97.74193548387096\n",
      "Precision :  7.142857142857142\n",
      "Recall :  50.0\n",
      "F1_score :  12.5\n",
      "Topic :  Gender division in daily life\n",
      "ACcuracy :  97.74193548387096\n",
      "Precision :  7.142857142857142\n",
      "Recall :  50.0\n",
      "F1_score :  12.5\n",
      "Topic :  Attraction  of social media \n",
      "ACcuracy :  99.51612903225806\n",
      "Precision :  50.0\n",
      "Recall :  33.33333333333333\n",
      "F1_score :  40.0\n",
      "Topic :  Peer pressure\n",
      "ACcuracy :  99.67741935483872\n",
      "Precision :  50.0\n",
      "Recall :  50.0\n",
      "F1_score :  50.0\n",
      "Topic :  Equality in a relationship\n",
      "ACcuracy :  99.51612903225806\n",
      "Precision :  33.33333333333333\n",
      "Recall :  50.0\n",
      "F1_score :  40.0\n",
      "Topic :  Safe sexual relationship\n",
      "ACcuracy :  98.87096774193549\n",
      "Precision :  14.285714285714285\n",
      "Recall :  50.0\n",
      "F1_score :  22.22222222222222\n",
      "Topic :  Female\n",
      "ACcuracy :  99.67741935483872\n",
      "Precision :  50.0\n",
      "Recall :  50.0\n",
      "F1_score :  50.0\n",
      "ACcuracy :  94.79753972321886\n",
      "Precision :  1.4563106796116505\n",
      "Recall :  1.4563106796116505\n",
      "F1_score :  1.4563106796116503\n"
     ]
    }
   ],
   "source": [
    "topics = reading_topics()\n",
    "data = reading_data(topics)\n",
    "data = cleaning(data)\n",
    "\n",
    "# print (len(data))\n",
    "data = stopwords_removal(data)\n",
    "\n",
    "tfdata = makeTF(data)\n",
    "idfdata = computeIDF(data)\n",
    "tfidfdata = makeTFIDF(tfdata, idfdata)\n",
    "sorted_tfidfdata = []\n",
    "for tfidf in tfidfdata:\n",
    "    sorted_tfidf = OrderedDict(sorted(tfidf.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    sorted_tfidfdata.append(sorted_tfidf)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# print (len(temp_topics))\n",
    "# print (len(sorted_tfidfdata))\n",
    "accuracymeasure()\n",
    "\n",
    "# for tfidf in sorted_tfidfdata:\n",
    "#     filename=\"./temp/\" + temp_topics[count] + \".txt\"\n",
    "#     file=open(filename, 'w')\n",
    "#     # print temp_topics[count]\n",
    "#     count = count + 1\n",
    "#     for word, val in tfidf.items():\n",
    "#         file.write(word + \" \" + str(val))\n",
    "#         file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
